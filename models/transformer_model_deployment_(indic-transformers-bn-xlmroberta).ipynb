{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import re\n",
    "from colorama import Fore, Back, Style\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_logical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('dataset/maya_dataset.xlsx', engine = 'openpyxl')\n",
    "dataset = dataset.iloc[:, 0:2]\n",
    "df_1 = dataset.copy()\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "                                    u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
    "                                    u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
    "                                    u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
    "                                    u\"\\U0001F1E0-\\U0001F1FF\" # flags (iOS)\n",
    "                                    u\"\\U0001F97A\"\n",
    "                                    u\"\\U00002639\"\n",
    "                                    u\"\\U0001F642\"\n",
    "                                    u\"\\U00002764\"\n",
    "                                    u\"\\U0001F600-\\U000E007F\"\n",
    "                                    \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r' ',text)\n",
    "def depunctuate(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"u\"\\/\"u\"\\\\\"u\"\\^\"u\"\\!\"u\"\\@\"u\"\\+\"u\"\\*\"u\"\\=\"u\"\\%\"u\"\\&\"u\"\\:\"u\"\\;\"u\"\\_\"u\"\\.\"u\"\\,\"u\"\\(\"u\"\\)\"u\"\\?\"u\"\\।\"u\"\\|\"u\"'\"u\"\\-\"u\"\\\"\"u\"]+\")\n",
    "    return regrex_pattern.sub(r' ',text)\n",
    "def denumerize(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[0-9০১২৩৪৫৬৭৮৯]+\")\n",
    "    return regrex_pattern.sub(r' ',text)\n",
    "def remove_empty_string_literals(string_list):\n",
    "    while(\"\" in string_list) :\n",
    "        string_list.remove(\"\")\n",
    "    return string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4876, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in range(df_1.shape[0]):\n",
    "    df_1.iloc[i,0] = deEmojify(df_1.iloc[i,0])\n",
    "df_2 = df_1.copy()\n",
    "\n",
    "for i in range(df_2.shape[0]):\n",
    "    df_2.iloc[i,0] = denumerize(df_2.iloc[i,0])\n",
    "df_3 = df_2.copy()\n",
    "df_3['length'] = [len(remove_empty_string_literals(post.split(' '))) for post in df_3.iloc[:, 0]]\n",
    "LOWER_BOUND = 5\n",
    "UPPER_BOUND = 300\n",
    "df_4 = df_3[(df_3['length'] >= LOWER_BOUND) == True]\n",
    "df_4 = df_4[(df_4['length'] <= UPPER_BOUND) == True]\n",
    "\n",
    "df_5 = df_4.copy()\n",
    "\n",
    "for i in range(df_5.shape[0]):\n",
    "    df_5.iloc[i,0] = depunctuate(df_5.iloc[i,0])\n",
    "print(df_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spell-correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drr/.local/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from bnlp.corpus.util import remove_stopwords\n",
    "file = open('stopwords/stopwords-bn.txt', encoding = 'utf-8')\n",
    "stopwords = []\n",
    "for line in file:\n",
    "    stopwords.append(line.strip())\n",
    "file.close()\n",
    "stopwords = list(filter(None, stopwords))\n",
    "df_6 = df_5.iloc[:, 0:2].copy()\n",
    "for i in range(df_6.shape[0]):\n",
    "    df_6.iloc[i, 0] = ' '.join(remove_stopwords(df_6.iloc[i, 0], stopwords))\n",
    "y = df_6.iloc[:, 1:2].values\n",
    "\n",
    "corpus = df_6.iloc[:, 0].values\n",
    "y = df_6.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding y\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "y = np.array((enc.fit_transform(y)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6['raw_posts'] = df_4.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>posts</th>\n",
       "      <th>raw_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4891</th>\n",
       "      <td>3</td>\n",
       "      <td>আসসালামু আলাইকুম সিজারে বাচ্চা হয়েছে বাচ্চা ইন...</td>\n",
       "      <td>আসসালামু আলাইকুম। আমার সিজারে বাচ্চা হয়েছে   দ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>3</td>\n",
       "      <td>গর্ভবতী অবস্থায় মানসিক অশান্তি ডিপ্রেশনে কান্ন...</td>\n",
       "      <td>গর্ভবতী অবস্থায় মানসিক অশান্তি, ডিপ্রেশনে কান্...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>4</td>\n",
       "      <td>মানুষিক সমস্যাতে আছি হয় মরে শান্তি</td>\n",
       "      <td>আমি মানুষিক অনেক সমস্যাতে আছি ... মনে হয় মরে ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>4</td>\n",
       "      <td>হাই একজন বয়স এডমিশন দিব করোনার আটকে সবসময় ডিপ্...</td>\n",
       "      <td>হাই। আমি একজন মেয়ে।  আমার বয়স   বছর।  আমি এবার...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>3</td>\n",
       "      <td>ছয় ডিপ্রেশনে ভুগছি চিকিৎসা নিয়েছি কিছুতেই হচ্ছ...</td>\n",
       "      <td>আমি ছয় বছর ধরে ডিপ্রেশনে ভুগছি।অনেক চিকিৎসা নি...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                              posts  \\\n",
       "4891       3  আসসালামু আলাইকুম সিজারে বাচ্চা হয়েছে বাচ্চা ইন...   \n",
       "4892       3  গর্ভবতী অবস্থায় মানসিক অশান্তি ডিপ্রেশনে কান্ন...   \n",
       "4893       4                মানুষিক সমস্যাতে আছি হয় মরে শান্তি   \n",
       "4894       4  হাই একজন বয়স এডমিশন দিব করোনার আটকে সবসময় ডিপ্...   \n",
       "4895       3  ছয় ডিপ্রেশনে ভুগছি চিকিৎসা নিয়েছি কিছুতেই হচ্ছ...   \n",
       "\n",
       "                                              raw_posts  \n",
       "4891  আসসালামু আলাইকুম। আমার সিজারে বাচ্চা হয়েছে   দ...  \n",
       "4892  গর্ভবতী অবস্থায় মানসিক অশান্তি, ডিপ্রেশনে কান্...  \n",
       "4893  আমি মানুষিক অনেক সমস্যাতে আছি ... মনে হয় মরে ...  \n",
       "4894  হাই। আমি একজন মেয়ে।  আমার বয়স   বছর।  আমি এবার...  \n",
       "4895  আমি ছয় বছর ধরে ডিপ্রেশনে ভুগছি।অনেক চিকিৎসা নি...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_6 = df_6.reindex(columns=['labels', 'posts', 'raw_posts'])\n",
    "df_6.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305\n"
     ]
    }
   ],
   "source": [
    "input_size = int(UPPER_BOUND + 5)\n",
    "print(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\", add_special_tokens = True, \n",
    "                                                max_length = input_size, pad_to_max_length=True)\n",
    "# X\n",
    "sentences = df_6.iloc[:, -1:].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences, tokenizer):\n",
    "    input_ids, input_masks, input_segments = [],[],[]\n",
    "    for sentence in sentences:\n",
    "        inputs = tokenizer.batch_encode_plus(sentence, add_special_tokens=True, \n",
    "                                             max_length = input_size,\n",
    "                                             padding='max_length',\n",
    "                                             return_attention_mask = True, \n",
    "                                             return_token_type_ids = True,\n",
    "                                             truncation = True)\n",
    "\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        input_masks.append(inputs['attention_mask'])\n",
    "        input_segments.append(inputs['token_type_ids'])\n",
    "\n",
    "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, input_masks, input_segments = tokenize(sentences = sentences, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(sentences, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "x_train = tokenize(x_train, tokenizer)\n",
    "x_train = [np.squeeze(x_train[0]), np.squeeze(x_train[1]), np.squeeze(x_train[2])]\n",
    "\n",
    "x_test = tokenize(x_test, tokenizer)\n",
    "x_test = [np.squeeze(x_test[0]), np.squeeze(x_test[1]), np.squeeze(x_test[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight(class_weight = 'balanced',\n",
    "                                                  classes = np.unique(np.reshape(enc.inverse_transform(y_train), y_train.shape[0])),\n",
    "                                                  y = np.reshape(enc.inverse_transform(y_train), y_train.shape[0]))\n",
    "class_weights = {0 : class_weights[0],\n",
    "               1 : class_weights[1],\n",
    "               2 : class_weights[2],\n",
    "               3 : class_weights[3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "ACCURACY_THRESHOLD = 0.85\n",
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs = {}): \n",
    "        if(logs.get('val_accuracy') > ACCURACY_THRESHOLD):   \n",
    "            print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))   \n",
    "            self.model.stop_training = True\n",
    "acc_threshold = myCallback()\n",
    "\n",
    "# save best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath = 'saved-models/BERT-BiGRU-test.epoch{epoch:02d}-loss{val_loss:.2f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath = filepath, \n",
    "                             monitor = 'val_accuracy',\n",
    "                             verbose = 1, \n",
    "                             save_best_only = True,\n",
    "                             mode = 'max')\n",
    "\n",
    "\n",
    "cosine_decay = tf.optimizers.schedules.CosineDecay(initial_learning_rate = lr, \n",
    "                                                   decay_steps = 1000)\n",
    "lr_scheduler_1 = tf.keras.callbacks.LearningRateScheduler(cosine_decay)\n",
    "\n",
    "cosine_decay_with_restarts = tf.optimizers.schedules.CosineDecayRestarts(initial_learning_rate = lr,\n",
    "                                                                        first_decay_steps = 1000,\n",
    "                                                                        m_mul = 0.1)\n",
    "lr_scheduler_2 = tf.keras.callbacks.LearningRateScheduler(cosine_decay_with_restarts)\n",
    "\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "tensor_board = TensorBoard(log_dir = 'tb_logs_BERT-BiGRU',\n",
    "                           update_freq = 1)\n",
    "from keras.callbacks import EarlyStopping\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at neuralspace-reverie/indic-transformers-bn-xlmroberta were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at neuralspace-reverie/indic-transformers-bn-xlmroberta.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "transformer_model = transformers.TFAutoModel.from_pretrained('neuralspace-reverie/indic-transformers-bn-xlmroberta')\n",
    "\n",
    "input_ids_in = tf.keras.layers.Input(shape=(input_size,), name='input_token', dtype=tf.int32)\n",
    "\n",
    "input_masks_in = tf.keras.layers.Input(shape=(input_size,), name='masked_token', dtype=tf.int32)\n",
    "\n",
    "input_segments_in = tf.keras.layers.Input(shape=(input_size,), name='segment_token', dtype=tf.int32)\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "embedding_layer = transformer_model(input_ids=input_ids_in, attention_mask=input_masks_in, token_type_ids = input_segments_in)[0]\n",
    "# X = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(150, return_sequences=True, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))(embedding_layer)\n",
    "# X = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(150, return_sequences=True, go_backwards=True, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))(X)\n",
    "X = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(150, return_sequences=True, dropout=0.1))(embedding_layer)\n",
    "X = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(150, return_sequences=True, go_backwards=True, dropout=0.1))(X)\n",
    "X = tf.keras.layers.GlobalMaxPooling1D()(X)\n",
    "X = tf.keras.layers.Dense(4096, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(X)\n",
    "# X = tf.keras.layers.Dense(1024, activation='relu')(X)\n",
    "# X = tf.keras.layers.Dense(1024, activation='relu')(X)\n",
    "X = tf.keras.layers.Dropout(0.1)(X)\n",
    "X = tf.keras.layers.Dense(4, activation='softmax')(X)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids_in, input_masks_in, input_segments_in], outputs = X)\n",
    "\n",
    "for layer in model.layers[:4]:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_token (InputLayer)       [(None, 305)]        0           []                               \n",
      "                                                                                                  \n",
      " masked_token (InputLayer)      [(None, 305)]        0           []                               \n",
      "                                                                                                  \n",
      " segment_token (InputLayer)     [(None, 305)]        0           []                               \n",
      "                                                                                                  \n",
      " tfxlm_roberta_model_3 (TFXLMRo  TFBaseModelOutputWi  134490624  ['input_token[0][0]',            \n",
      " bertaModel)                    thPoolingAndCrossAt               'masked_token[0][0]',           \n",
      "                                tentions(last_hidde               'segment_token[0][0]']          \n",
      "                                n_state=(None, 305,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " bidirectional_6 (Bidirectional  (None, 305, 300)    828000      ['tfxlm_roberta_model_3[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_7 (Bidirectional  (None, 305, 300)    406800      ['bidirectional_6[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling1d_3 (Global  (None, 300)         0           ['bidirectional_7[0][0]']        \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 4096)         1232896     ['global_max_pooling1d_3[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_103 (Dropout)          (None, 4096)         0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 4)            16388       ['dropout_103[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 136,974,708\n",
      "Trainable params: 2,484,084\n",
      "Non-trainable params: 134,490,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=lr,\n",
    "                              amsgrad=True,\n",
    "                              name=\"Adam\",)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = opt,\n",
    "             weighted_metrics = 'accuracy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "320/320 [==============================] - 56s 154ms/step - loss: 4.9495 - accuracy: 0.4084 - val_loss: 3.6755 - val_accuracy: 0.5200 - lr: 1.0000e-04\n",
      "Epoch 2/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 3.0218 - accuracy: 0.5252 - val_loss: 2.4052 - val_accuracy: 0.6148 - lr: 1.0000e-04\n",
      "Epoch 3/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 2.1640 - accuracy: 0.5523 - val_loss: 1.9112 - val_accuracy: 0.5911 - lr: 9.9999e-05\n",
      "Epoch 4/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 1.6808 - accuracy: 0.5632 - val_loss: 1.4784 - val_accuracy: 0.6275 - lr: 9.9998e-05\n",
      "Epoch 5/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 1.3705 - accuracy: 0.6255 - val_loss: 1.2231 - val_accuracy: 0.6648 - lr: 9.9996e-05\n",
      "Epoch 6/400\n",
      "320/320 [==============================] - 47s 149ms/step - loss: 1.1475 - accuracy: 0.6540 - val_loss: 1.0680 - val_accuracy: 0.6821 - lr: 9.9994e-05\n",
      "Epoch 7/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.9994 - accuracy: 0.6836 - val_loss: 0.9625 - val_accuracy: 0.6958 - lr: 9.9991e-05\n",
      "Epoch 8/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.8929 - accuracy: 0.7072 - val_loss: 0.9519 - val_accuracy: 0.6794 - lr: 9.9988e-05\n",
      "Epoch 9/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.7911 - accuracy: 0.7424 - val_loss: 0.8441 - val_accuracy: 0.7350 - lr: 9.9984e-05\n",
      "Epoch 10/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.7274 - accuracy: 0.7584 - val_loss: 0.9409 - val_accuracy: 0.6740 - lr: 9.9980e-05\n",
      "Epoch 11/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.6722 - accuracy: 0.7665 - val_loss: 0.8184 - val_accuracy: 0.7158 - lr: 9.9975e-05\n",
      "Epoch 12/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.6236 - accuracy: 0.7861 - val_loss: 0.8039 - val_accuracy: 0.7186 - lr: 9.9970e-05\n",
      "Epoch 13/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.5890 - accuracy: 0.8009 - val_loss: 0.7733 - val_accuracy: 0.7441 - lr: 9.9964e-05\n",
      "Epoch 14/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.5482 - accuracy: 0.8143 - val_loss: 0.7959 - val_accuracy: 0.7477 - lr: 9.9958e-05\n",
      "Epoch 15/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.4941 - accuracy: 0.8377 - val_loss: 0.7727 - val_accuracy: 0.7450 - lr: 9.9952e-05\n",
      "Epoch 16/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.4429 - accuracy: 0.8577 - val_loss: 0.8370 - val_accuracy: 0.7058 - lr: 9.9944e-05\n",
      "Epoch 17/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.4187 - accuracy: 0.8694 - val_loss: 0.8306 - val_accuracy: 0.7213 - lr: 9.9937e-05\n",
      "Epoch 18/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.3852 - accuracy: 0.8878 - val_loss: 0.8448 - val_accuracy: 0.7687 - lr: 9.9929e-05\n",
      "Epoch 19/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.3615 - accuracy: 0.8972 - val_loss: 0.8464 - val_accuracy: 0.7441 - lr: 9.9920e-05\n",
      "Epoch 20/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.3470 - accuracy: 0.9012 - val_loss: 0.8351 - val_accuracy: 0.7650 - lr: 9.9911e-05\n",
      "Epoch 21/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.3253 - accuracy: 0.9111 - val_loss: 0.9631 - val_accuracy: 0.7040 - lr: 9.9901e-05\n",
      "Epoch 22/400\n",
      "320/320 [==============================] - 46s 145ms/step - loss: 0.2846 - accuracy: 0.9335 - val_loss: 0.8234 - val_accuracy: 0.7641 - lr: 9.9891e-05\n",
      "Epoch 23/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.2600 - accuracy: 0.9395 - val_loss: 0.8512 - val_accuracy: 0.7778 - lr: 9.9881e-05\n",
      "Epoch 24/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.2495 - accuracy: 0.9378 - val_loss: 0.8669 - val_accuracy: 0.7632 - lr: 9.9870e-05\n",
      "Epoch 25/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.2165 - accuracy: 0.9526 - val_loss: 0.8901 - val_accuracy: 0.7514 - lr: 9.9858e-05\n",
      "Epoch 26/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.2115 - accuracy: 0.9552 - val_loss: 0.8727 - val_accuracy: 0.7459 - lr: 9.9846e-05\n",
      "Epoch 27/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.1923 - accuracy: 0.9596 - val_loss: 0.8879 - val_accuracy: 0.7869 - lr: 9.9833e-05\n",
      "Epoch 28/400\n",
      "320/320 [==============================] - 47s 145ms/step - loss: 0.1759 - accuracy: 0.9682 - val_loss: 0.9499 - val_accuracy: 0.7450 - lr: 9.9820e-05\n",
      "Epoch 29/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.1749 - accuracy: 0.9685 - val_loss: 1.0327 - val_accuracy: 0.7341 - lr: 9.9807e-05\n",
      "Epoch 30/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.1639 - accuracy: 0.9708 - val_loss: 0.9809 - val_accuracy: 0.7322 - lr: 9.9793e-05\n",
      "Epoch 31/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.1583 - accuracy: 0.9657 - val_loss: 0.9310 - val_accuracy: 0.7423 - lr: 9.9778e-05\n",
      "Epoch 32/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.1468 - accuracy: 0.9736 - val_loss: 0.8812 - val_accuracy: 0.7605 - lr: 9.9763e-05\n",
      "Epoch 33/400\n",
      "320/320 [==============================] - 49s 153ms/step - loss: 0.1457 - accuracy: 0.9712 - val_loss: 0.9054 - val_accuracy: 0.7632 - lr: 9.9748e-05\n",
      "Epoch 34/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.1403 - accuracy: 0.9783 - val_loss: 0.8880 - val_accuracy: 0.7778 - lr: 9.9732e-05\n",
      "Epoch 35/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.1085 - accuracy: 0.9881 - val_loss: 0.9278 - val_accuracy: 0.7587 - lr: 9.9715e-05\n",
      "Epoch 36/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.1213 - accuracy: 0.9784 - val_loss: 1.0224 - val_accuracy: 0.7732 - lr: 9.9698e-05\n",
      "Epoch 37/400\n",
      "320/320 [==============================] - 48s 151ms/step - loss: 0.1154 - accuracy: 0.9800 - val_loss: 0.9511 - val_accuracy: 0.7668 - lr: 9.9681e-05\n",
      "Epoch 38/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.1093 - accuracy: 0.9823 - val_loss: 0.9400 - val_accuracy: 0.7668 - lr: 9.9663e-05\n",
      "Epoch 39/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0883 - accuracy: 0.9911 - val_loss: 1.0098 - val_accuracy: 0.7577 - lr: 9.9644e-05\n",
      "Epoch 40/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0824 - accuracy: 0.9926 - val_loss: 0.9472 - val_accuracy: 0.7623 - lr: 9.9625e-05\n",
      "Epoch 41/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0926 - accuracy: 0.9859 - val_loss: 1.0073 - val_accuracy: 0.7486 - lr: 9.9606e-05\n",
      "Epoch 42/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0878 - accuracy: 0.9879 - val_loss: 0.9646 - val_accuracy: 0.7678 - lr: 9.9586e-05\n",
      "Epoch 43/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0831 - accuracy: 0.9888 - val_loss: 0.9800 - val_accuracy: 0.7659 - lr: 9.9565e-05\n",
      "Epoch 44/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0789 - accuracy: 0.9913 - val_loss: 0.9797 - val_accuracy: 0.7805 - lr: 9.9544e-05\n",
      "Epoch 45/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0808 - accuracy: 0.9870 - val_loss: 0.9777 - val_accuracy: 0.7823 - lr: 9.9523e-05\n",
      "Epoch 46/400\n",
      "320/320 [==============================] - 48s 151ms/step - loss: 0.0804 - accuracy: 0.9895 - val_loss: 0.9701 - val_accuracy: 0.7851 - lr: 9.9501e-05\n",
      "Epoch 47/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0860 - accuracy: 0.9863 - val_loss: 0.9633 - val_accuracy: 0.7632 - lr: 9.9479e-05\n",
      "Epoch 48/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0777 - accuracy: 0.9893 - val_loss: 1.0074 - val_accuracy: 0.7760 - lr: 9.9456e-05\n",
      "Epoch 49/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0788 - accuracy: 0.9884 - val_loss: 1.1602 - val_accuracy: 0.7450 - lr: 9.9433e-05\n",
      "Epoch 50/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0777 - accuracy: 0.9893 - val_loss: 1.0572 - val_accuracy: 0.7587 - lr: 9.9409e-05\n",
      "Epoch 51/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 49s 154ms/step - loss: 0.0640 - accuracy: 0.9924 - val_loss: 1.0105 - val_accuracy: 0.7641 - lr: 9.9384e-05\n",
      "Epoch 52/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0597 - accuracy: 0.9951 - val_loss: 1.0696 - val_accuracy: 0.7750 - lr: 9.9360e-05\n",
      "Epoch 53/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0636 - accuracy: 0.9922 - val_loss: 1.0175 - val_accuracy: 0.7614 - lr: 9.9334e-05\n",
      "Epoch 54/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0600 - accuracy: 0.9940 - val_loss: 1.0470 - val_accuracy: 0.7842 - lr: 9.9308e-05\n",
      "Epoch 55/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0549 - accuracy: 0.9958 - val_loss: 1.0820 - val_accuracy: 0.7796 - lr: 9.9282e-05\n",
      "Epoch 56/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0541 - accuracy: 0.9955 - val_loss: 1.0855 - val_accuracy: 0.7823 - lr: 9.9255e-05\n",
      "Epoch 57/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0460 - accuracy: 0.9985 - val_loss: 1.0794 - val_accuracy: 0.7641 - lr: 9.9228e-05\n",
      "Epoch 58/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0435 - accuracy: 0.9978 - val_loss: 0.9954 - val_accuracy: 0.7778 - lr: 9.9200e-05\n",
      "Epoch 59/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0437 - accuracy: 0.9961 - val_loss: 1.0190 - val_accuracy: 0.7705 - lr: 9.9172e-05\n",
      "Epoch 60/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0485 - accuracy: 0.9940 - val_loss: 1.0087 - val_accuracy: 0.7668 - lr: 9.9144e-05\n",
      "Epoch 61/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0590 - accuracy: 0.9899 - val_loss: 1.0550 - val_accuracy: 0.7741 - lr: 9.9114e-05\n",
      "Epoch 62/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0444 - accuracy: 0.9969 - val_loss: 1.0096 - val_accuracy: 0.7641 - lr: 9.9085e-05\n",
      "Epoch 63/400\n",
      "320/320 [==============================] - 49s 152ms/step - loss: 0.0664 - accuracy: 0.9885 - val_loss: 0.9895 - val_accuracy: 0.7769 - lr: 9.9055e-05\n",
      "Epoch 64/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0552 - accuracy: 0.9932 - val_loss: 1.0933 - val_accuracy: 0.7723 - lr: 9.9024e-05\n",
      "Epoch 65/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0621 - accuracy: 0.9895 - val_loss: 1.0981 - val_accuracy: 0.7823 - lr: 9.8993e-05\n",
      "Epoch 66/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0530 - accuracy: 0.9931 - val_loss: 1.0743 - val_accuracy: 0.7842 - lr: 9.8961e-05\n",
      "Epoch 67/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0414 - accuracy: 0.9960 - val_loss: 1.1182 - val_accuracy: 0.7823 - lr: 9.8929e-05\n",
      "Epoch 68/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0574 - accuracy: 0.9890 - val_loss: 1.0502 - val_accuracy: 0.7559 - lr: 9.8896e-05\n",
      "Epoch 69/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0367 - accuracy: 0.9983 - val_loss: 1.0282 - val_accuracy: 0.7678 - lr: 9.8863e-05\n",
      "Epoch 70/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0454 - accuracy: 0.9956 - val_loss: 1.0909 - val_accuracy: 0.7741 - lr: 9.8830e-05\n",
      "Epoch 71/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0359 - accuracy: 0.9972 - val_loss: 1.0551 - val_accuracy: 0.7814 - lr: 9.8796e-05\n",
      "Epoch 72/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0513 - accuracy: 0.9909 - val_loss: 1.2126 - val_accuracy: 0.7760 - lr: 9.8761e-05\n",
      "Epoch 73/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0383 - accuracy: 0.9983 - val_loss: 1.1062 - val_accuracy: 0.7878 - lr: 9.8726e-05\n",
      "Epoch 74/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0330 - accuracy: 0.9980 - val_loss: 1.0932 - val_accuracy: 0.7741 - lr: 9.8691e-05\n",
      "Epoch 75/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0349 - accuracy: 0.9966 - val_loss: 1.0347 - val_accuracy: 0.7787 - lr: 9.8655e-05\n",
      "Epoch 76/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0376 - accuracy: 0.9953 - val_loss: 1.2853 - val_accuracy: 0.7477 - lr: 9.8618e-05\n",
      "Epoch 77/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0486 - accuracy: 0.9929 - val_loss: 1.0786 - val_accuracy: 0.7668 - lr: 9.8582e-05\n",
      "Epoch 78/400\n",
      "320/320 [==============================] - 48s 151ms/step - loss: 0.0365 - accuracy: 0.9963 - val_loss: 1.0904 - val_accuracy: 0.7641 - lr: 9.8544e-05\n",
      "Epoch 79/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0326 - accuracy: 0.9975 - val_loss: 1.0893 - val_accuracy: 0.7732 - lr: 9.8506e-05\n",
      "Epoch 80/400\n",
      "320/320 [==============================] - 49s 152ms/step - loss: 0.0297 - accuracy: 0.9987 - val_loss: 1.0624 - val_accuracy: 0.7750 - lr: 9.8468e-05\n",
      "Epoch 81/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0273 - accuracy: 0.9992 - val_loss: 1.0711 - val_accuracy: 0.7860 - lr: 9.8429e-05\n",
      "Epoch 82/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0397 - accuracy: 0.9947 - val_loss: 1.1211 - val_accuracy: 0.7832 - lr: 9.8390e-05\n",
      "Epoch 83/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0325 - accuracy: 0.9971 - val_loss: 1.1118 - val_accuracy: 0.7832 - lr: 9.8350e-05\n",
      "Epoch 84/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0325 - accuracy: 0.9962 - val_loss: 1.0614 - val_accuracy: 0.7832 - lr: 9.8310e-05\n",
      "Epoch 85/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0302 - accuracy: 0.9963 - val_loss: 1.1023 - val_accuracy: 0.7641 - lr: 9.8269e-05\n",
      "Epoch 86/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0316 - accuracy: 0.9960 - val_loss: 1.2177 - val_accuracy: 0.7778 - lr: 9.8228e-05\n",
      "Epoch 87/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0306 - accuracy: 0.9968 - val_loss: 1.1130 - val_accuracy: 0.7541 - lr: 9.8186e-05\n",
      "Epoch 88/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0325 - accuracy: 0.9973 - val_loss: 1.0566 - val_accuracy: 0.7750 - lr: 9.8144e-05\n",
      "Epoch 89/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0252 - accuracy: 0.9995 - val_loss: 1.0350 - val_accuracy: 0.7732 - lr: 9.8101e-05\n",
      "Epoch 90/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0283 - accuracy: 0.9976 - val_loss: 1.1296 - val_accuracy: 0.7760 - lr: 9.8058e-05\n",
      "Epoch 91/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0342 - accuracy: 0.9956 - val_loss: 1.1127 - val_accuracy: 0.7760 - lr: 9.8015e-05\n",
      "Epoch 92/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0383 - accuracy: 0.9956 - val_loss: 1.1524 - val_accuracy: 0.7796 - lr: 9.7971e-05\n",
      "Epoch 93/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0371 - accuracy: 0.9945 - val_loss: 1.1786 - val_accuracy: 0.7723 - lr: 9.7926e-05\n",
      "Epoch 94/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0434 - accuracy: 0.9938 - val_loss: 1.1254 - val_accuracy: 0.7805 - lr: 9.7881e-05\n",
      "Epoch 95/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0293 - accuracy: 0.9977 - val_loss: 1.1680 - val_accuracy: 0.7769 - lr: 9.7836e-05\n",
      "Epoch 96/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0662 - accuracy: 0.9874 - val_loss: 1.0336 - val_accuracy: 0.7714 - lr: 9.7790e-05\n",
      "Epoch 97/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0321 - accuracy: 0.9998 - val_loss: 1.1140 - val_accuracy: 0.7805 - lr: 9.7743e-05\n",
      "Epoch 98/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0299 - accuracy: 0.9972 - val_loss: 1.1027 - val_accuracy: 0.7732 - lr: 9.7696e-05\n",
      "Epoch 99/400\n",
      "320/320 [==============================] - 49s 154ms/step - loss: 0.0274 - accuracy: 0.9979 - val_loss: 1.0737 - val_accuracy: 0.7750 - lr: 9.7649e-05\n",
      "Epoch 100/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0228 - accuracy: 0.9994 - val_loss: 1.0477 - val_accuracy: 0.7723 - lr: 9.7601e-05\n",
      "Epoch 101/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0222 - accuracy: 0.9990 - val_loss: 1.0649 - val_accuracy: 0.7832 - lr: 9.7553e-05\n",
      "Epoch 102/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0204 - accuracy: 0.9989 - val_loss: 1.0414 - val_accuracy: 0.7796 - lr: 9.7504e-05\n",
      "Epoch 103/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0192 - accuracy: 0.9995 - val_loss: 1.0457 - val_accuracy: 0.7851 - lr: 9.7455e-05\n",
      "Epoch 104/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0195 - accuracy: 0.9997 - val_loss: 1.0545 - val_accuracy: 0.7796 - lr: 9.7405e-05\n",
      "Epoch 105/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0187 - accuracy: 0.9995 - val_loss: 1.0469 - val_accuracy: 0.7769 - lr: 9.7355e-05\n",
      "Epoch 106/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0198 - accuracy: 0.9992 - val_loss: 1.1197 - val_accuracy: 0.7668 - lr: 9.7304e-05\n",
      "Epoch 107/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0234 - accuracy: 0.9972 - val_loss: 1.0816 - val_accuracy: 0.7769 - lr: 9.7253e-05\n",
      "Epoch 108/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.0909 - val_accuracy: 0.7796 - lr: 9.7202e-05\n",
      "Epoch 109/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0187 - accuracy: 0.9995 - val_loss: 1.0699 - val_accuracy: 0.7741 - lr: 9.7150e-05\n",
      "Epoch 110/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0169 - accuracy: 0.9995 - val_loss: 1.0702 - val_accuracy: 0.7760 - lr: 9.7097e-05\n",
      "Epoch 111/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0194 - accuracy: 0.9984 - val_loss: 1.1504 - val_accuracy: 0.7878 - lr: 9.7044e-05\n",
      "Epoch 112/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0195 - accuracy: 0.9988 - val_loss: 1.0664 - val_accuracy: 0.7842 - lr: 9.6991e-05\n",
      "Epoch 113/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0253 - accuracy: 0.9975 - val_loss: 1.2200 - val_accuracy: 0.7851 - lr: 9.6937e-05\n",
      "Epoch 114/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0218 - accuracy: 0.9985 - val_loss: 1.0720 - val_accuracy: 0.7760 - lr: 9.6882e-05\n",
      "Epoch 115/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0203 - accuracy: 0.9990 - val_loss: 1.1107 - val_accuracy: 0.7659 - lr: 9.6827e-05\n",
      "Epoch 116/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0241 - accuracy: 0.9964 - val_loss: 1.0890 - val_accuracy: 0.7732 - lr: 9.6772e-05\n",
      "Epoch 117/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0298 - accuracy: 0.9962 - val_loss: 1.2055 - val_accuracy: 0.7805 - lr: 9.6716e-05\n",
      "Epoch 118/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0291 - accuracy: 0.9961 - val_loss: 1.1342 - val_accuracy: 0.7741 - lr: 9.6660e-05\n",
      "Epoch 119/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 1.2038 - val_accuracy: 0.7714 - lr: 9.6604e-05\n",
      "Epoch 120/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0375 - accuracy: 0.9929 - val_loss: 1.1760 - val_accuracy: 0.7778 - lr: 9.6546e-05\n",
      "Epoch 121/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0208 - accuracy: 0.9990 - val_loss: 1.1299 - val_accuracy: 0.7778 - lr: 9.6489e-05\n",
      "Epoch 122/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0234 - accuracy: 0.9969 - val_loss: 1.1336 - val_accuracy: 0.7805 - lr: 9.6431e-05\n",
      "Epoch 123/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0228 - accuracy: 0.9985 - val_loss: 1.1084 - val_accuracy: 0.7832 - lr: 9.6372e-05\n",
      "Epoch 124/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0193 - accuracy: 0.9981 - val_loss: 1.1059 - val_accuracy: 0.7842 - lr: 9.6313e-05\n",
      "Epoch 125/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0171 - accuracy: 0.9995 - val_loss: 1.1202 - val_accuracy: 0.7787 - lr: 9.6254e-05\n",
      "Epoch 126/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0185 - accuracy: 0.9989 - val_loss: 1.1135 - val_accuracy: 0.7796 - lr: 9.6194e-05\n",
      "Epoch 127/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0163 - accuracy: 0.9995 - val_loss: 1.1592 - val_accuracy: 0.7923 - lr: 9.6134e-05\n",
      "Epoch 128/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0396 - accuracy: 0.9898 - val_loss: 1.1889 - val_accuracy: 0.7732 - lr: 9.6073e-05\n",
      "Epoch 129/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0238 - accuracy: 0.9977 - val_loss: 1.1649 - val_accuracy: 0.7805 - lr: 9.6012e-05\n",
      "Epoch 130/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0183 - accuracy: 0.9987 - val_loss: 1.2287 - val_accuracy: 0.7842 - lr: 9.5950e-05\n",
      "Epoch 131/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0166 - accuracy: 0.9997 - val_loss: 1.1215 - val_accuracy: 0.7587 - lr: 9.5888e-05\n",
      "Epoch 132/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0192 - accuracy: 0.9986 - val_loss: 1.1413 - val_accuracy: 0.7659 - lr: 9.5825e-05\n",
      "Epoch 133/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.1361 - val_accuracy: 0.7842 - lr: 9.5762e-05\n",
      "Epoch 134/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0145 - accuracy: 0.9995 - val_loss: 1.1048 - val_accuracy: 0.7769 - lr: 9.5699e-05\n",
      "Epoch 135/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0243 - accuracy: 0.9974 - val_loss: 1.1745 - val_accuracy: 0.7869 - lr: 9.5635e-05\n",
      "Epoch 136/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0185 - accuracy: 0.9984 - val_loss: 1.1734 - val_accuracy: 0.7878 - lr: 9.5570e-05\n",
      "Epoch 137/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0187 - accuracy: 0.9989 - val_loss: 1.0950 - val_accuracy: 0.7741 - lr: 9.5505e-05\n",
      "Epoch 138/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0193 - accuracy: 0.9974 - val_loss: 1.1588 - val_accuracy: 0.7796 - lr: 9.5440e-05\n",
      "Epoch 139/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0274 - accuracy: 0.9966 - val_loss: 1.1297 - val_accuracy: 0.7796 - lr: 9.5374e-05\n",
      "Epoch 140/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0188 - accuracy: 0.9990 - val_loss: 1.0941 - val_accuracy: 0.7732 - lr: 9.5308e-05\n",
      "Epoch 141/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.1659 - val_accuracy: 0.7750 - lr: 9.5241e-05\n",
      "Epoch 142/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0163 - accuracy: 0.9988 - val_loss: 1.1603 - val_accuracy: 0.7842 - lr: 9.5174e-05\n",
      "Epoch 143/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0226 - accuracy: 0.9960 - val_loss: 1.1383 - val_accuracy: 0.7732 - lr: 9.5107e-05\n",
      "Epoch 144/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0219 - accuracy: 0.9977 - val_loss: 1.1433 - val_accuracy: 0.7760 - lr: 9.5039e-05\n",
      "Epoch 145/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0156 - accuracy: 0.9992 - val_loss: 1.1869 - val_accuracy: 0.7869 - lr: 9.4970e-05\n",
      "Epoch 146/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0391 - accuracy: 0.9922 - val_loss: 1.1357 - val_accuracy: 0.7796 - lr: 9.4901e-05\n",
      "Epoch 147/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0227 - accuracy: 0.9981 - val_loss: 1.1595 - val_accuracy: 0.7732 - lr: 9.4832e-05\n",
      "Epoch 148/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0190 - accuracy: 0.9987 - val_loss: 1.1233 - val_accuracy: 0.7796 - lr: 9.4762e-05\n",
      "Epoch 149/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0217 - accuracy: 0.9974 - val_loss: 1.1501 - val_accuracy: 0.7814 - lr: 9.4692e-05\n",
      "Epoch 150/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.1274 - val_accuracy: 0.7760 - lr: 9.4621e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.1171 - val_accuracy: 0.7750 - lr: 9.4550e-05\n",
      "Epoch 152/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0217 - accuracy: 0.9970 - val_loss: 1.2461 - val_accuracy: 0.7778 - lr: 9.4479e-05\n",
      "Epoch 153/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0240 - accuracy: 0.9955 - val_loss: 1.2039 - val_accuracy: 0.7796 - lr: 9.4407e-05\n",
      "Epoch 154/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0233 - accuracy: 0.9984 - val_loss: 1.2009 - val_accuracy: 0.7732 - lr: 9.4334e-05\n",
      "Epoch 155/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0220 - accuracy: 0.9973 - val_loss: 1.2031 - val_accuracy: 0.7814 - lr: 9.4262e-05\n",
      "Epoch 156/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0161 - accuracy: 0.9989 - val_loss: 1.1428 - val_accuracy: 0.7805 - lr: 9.4188e-05\n",
      "Epoch 157/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0155 - accuracy: 0.9989 - val_loss: 1.2030 - val_accuracy: 0.7842 - lr: 9.4115e-05\n",
      "Epoch 158/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0214 - accuracy: 0.9978 - val_loss: 1.1084 - val_accuracy: 0.7605 - lr: 9.4040e-05\n",
      "Epoch 159/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0230 - accuracy: 0.9943 - val_loss: 1.3825 - val_accuracy: 0.7213 - lr: 9.3966e-05\n",
      "Epoch 160/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0249 - accuracy: 0.9975 - val_loss: 1.1475 - val_accuracy: 0.7878 - lr: 9.3891e-05\n",
      "Epoch 161/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0144 - accuracy: 0.9998 - val_loss: 1.1343 - val_accuracy: 0.7896 - lr: 9.3815e-05\n",
      "Epoch 162/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0167 - accuracy: 0.9990 - val_loss: 1.1038 - val_accuracy: 0.7814 - lr: 9.3739e-05\n",
      "Epoch 163/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0153 - accuracy: 0.9990 - val_loss: 1.1772 - val_accuracy: 0.7887 - lr: 9.3663e-05\n",
      "Epoch 164/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0174 - accuracy: 0.9979 - val_loss: 1.2403 - val_accuracy: 0.7741 - lr: 9.3586e-05\n",
      "Epoch 165/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0147 - accuracy: 0.9995 - val_loss: 1.1567 - val_accuracy: 0.7860 - lr: 9.3509e-05\n",
      "Epoch 166/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0119 - accuracy: 0.9997 - val_loss: 1.1162 - val_accuracy: 0.7778 - lr: 9.3432e-05\n",
      "Epoch 167/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0151 - accuracy: 0.9990 - val_loss: 1.1654 - val_accuracy: 0.7769 - lr: 9.3354e-05\n",
      "Epoch 168/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0136 - accuracy: 0.9993 - val_loss: 1.1482 - val_accuracy: 0.7760 - lr: 9.3275e-05\n",
      "Epoch 169/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.1205 - val_accuracy: 0.7760 - lr: 9.3196e-05\n",
      "Epoch 170/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0118 - accuracy: 0.9995 - val_loss: 1.1085 - val_accuracy: 0.7905 - lr: 9.3117e-05\n",
      "Epoch 171/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.0920 - val_accuracy: 0.7860 - lr: 9.3037e-05\n",
      "Epoch 172/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0102 - accuracy: 0.9998 - val_loss: 1.2025 - val_accuracy: 0.7832 - lr: 9.2957e-05\n",
      "Epoch 173/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0120 - accuracy: 0.9990 - val_loss: 1.1829 - val_accuracy: 0.7842 - lr: 9.2876e-05\n",
      "Epoch 174/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0140 - accuracy: 0.9981 - val_loss: 1.2728 - val_accuracy: 0.7905 - lr: 9.2795e-05\n",
      "Epoch 175/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0274 - accuracy: 0.9954 - val_loss: 1.1783 - val_accuracy: 0.7778 - lr: 9.2714e-05\n",
      "Epoch 176/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0327 - accuracy: 0.9931 - val_loss: 1.3054 - val_accuracy: 0.7760 - lr: 9.2632e-05\n",
      "Epoch 177/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0245 - accuracy: 0.9967 - val_loss: 1.2185 - val_accuracy: 0.7796 - lr: 9.2550e-05\n",
      "Epoch 178/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0292 - accuracy: 0.9931 - val_loss: 1.2975 - val_accuracy: 0.7250 - lr: 9.2467e-05\n",
      "Epoch 179/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0371 - accuracy: 0.9931 - val_loss: 1.3693 - val_accuracy: 0.7842 - lr: 9.2384e-05\n",
      "Epoch 180/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0211 - accuracy: 0.9993 - val_loss: 1.2587 - val_accuracy: 0.7823 - lr: 9.2300e-05\n",
      "Epoch 181/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0521 - accuracy: 0.9865 - val_loss: 1.3334 - val_accuracy: 0.7851 - lr: 9.2216e-05\n",
      "Epoch 182/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0250 - accuracy: 0.9984 - val_loss: 1.2593 - val_accuracy: 0.7532 - lr: 9.2132e-05\n",
      "Epoch 183/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0175 - accuracy: 0.9992 - val_loss: 1.1792 - val_accuracy: 0.7851 - lr: 9.2047e-05\n",
      "Epoch 184/400\n",
      "320/320 [==============================] - 49s 154ms/step - loss: 0.0193 - accuracy: 0.9976 - val_loss: 1.2958 - val_accuracy: 0.7714 - lr: 9.1962e-05\n",
      "Epoch 185/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0188 - accuracy: 0.9988 - val_loss: 1.1936 - val_accuracy: 0.7787 - lr: 9.1876e-05\n",
      "Epoch 186/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0152 - accuracy: 0.9988 - val_loss: 1.1966 - val_accuracy: 0.7687 - lr: 9.1790e-05\n",
      "Epoch 187/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0142 - accuracy: 0.9995 - val_loss: 1.1484 - val_accuracy: 0.7732 - lr: 9.1704e-05\n",
      "Epoch 188/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.1043 - val_accuracy: 0.7750 - lr: 9.1617e-05\n",
      "Epoch 189/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0133 - accuracy: 0.9992 - val_loss: 1.1358 - val_accuracy: 0.7805 - lr: 9.1530e-05\n",
      "Epoch 190/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.1243 - val_accuracy: 0.7832 - lr: 9.1442e-05\n",
      "Epoch 191/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0121 - accuracy: 0.9998 - val_loss: 1.1409 - val_accuracy: 0.7769 - lr: 9.1354e-05\n",
      "Epoch 192/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0124 - accuracy: 0.9992 - val_loss: 1.1249 - val_accuracy: 0.7805 - lr: 9.1266e-05\n",
      "Epoch 193/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0103 - accuracy: 0.9998 - val_loss: 1.1150 - val_accuracy: 0.7860 - lr: 9.1177e-05\n",
      "Epoch 194/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0117 - accuracy: 0.9992 - val_loss: 1.1144 - val_accuracy: 0.7860 - lr: 9.1087e-05\n",
      "Epoch 195/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.0917 - val_accuracy: 0.7914 - lr: 9.0998e-05\n",
      "Epoch 196/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0098 - accuracy: 0.9998 - val_loss: 1.1153 - val_accuracy: 0.7933 - lr: 9.0907e-05\n",
      "Epoch 197/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 1.1072 - val_accuracy: 0.7814 - lr: 9.0817e-05\n",
      "Epoch 198/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0107 - accuracy: 0.9997 - val_loss: 1.1214 - val_accuracy: 0.7796 - lr: 9.0726e-05\n",
      "Epoch 199/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0108 - accuracy: 0.9995 - val_loss: 1.0848 - val_accuracy: 0.7869 - lr: 9.0635e-05\n",
      "Epoch 200/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0127 - accuracy: 0.9988 - val_loss: 1.1195 - val_accuracy: 0.7732 - lr: 9.0543e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0155 - accuracy: 0.9982 - val_loss: 1.1589 - val_accuracy: 0.7787 - lr: 9.0451e-05\n",
      "Epoch 202/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0118 - accuracy: 0.9990 - val_loss: 1.1694 - val_accuracy: 0.7741 - lr: 9.0358e-05\n",
      "Epoch 203/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0160 - accuracy: 0.9978 - val_loss: 1.1660 - val_accuracy: 0.7632 - lr: 9.0265e-05\n",
      "Epoch 204/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0125 - accuracy: 0.9989 - val_loss: 1.1580 - val_accuracy: 0.7778 - lr: 9.0172e-05\n",
      "Epoch 205/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0131 - accuracy: 0.9985 - val_loss: 1.2371 - val_accuracy: 0.7805 - lr: 9.0078e-05\n",
      "Epoch 206/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0104 - accuracy: 0.9995 - val_loss: 1.1964 - val_accuracy: 0.7796 - lr: 8.9984e-05\n",
      "Epoch 207/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0102 - accuracy: 0.9998 - val_loss: 1.1613 - val_accuracy: 0.7805 - lr: 8.9890e-05\n",
      "Epoch 208/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1454 - val_accuracy: 0.7842 - lr: 8.9795e-05\n",
      "Epoch 209/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0110 - accuracy: 0.9990 - val_loss: 1.1828 - val_accuracy: 0.7641 - lr: 8.9700e-05\n",
      "Epoch 210/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1727 - val_accuracy: 0.7732 - lr: 8.9604e-05\n",
      "Epoch 211/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.1452 - val_accuracy: 0.7778 - lr: 8.9508e-05\n",
      "Epoch 212/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 1.1853 - val_accuracy: 0.7641 - lr: 8.9411e-05\n",
      "Epoch 213/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0142 - accuracy: 0.9982 - val_loss: 1.1738 - val_accuracy: 0.7678 - lr: 8.9314e-05\n",
      "Epoch 214/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0282 - accuracy: 0.9933 - val_loss: 1.3127 - val_accuracy: 0.7787 - lr: 8.9217e-05\n",
      "Epoch 215/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0208 - accuracy: 0.9971 - val_loss: 1.2394 - val_accuracy: 0.7723 - lr: 8.9120e-05\n",
      "Epoch 216/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0128 - accuracy: 0.9994 - val_loss: 1.2341 - val_accuracy: 0.7805 - lr: 8.9022e-05\n",
      "Epoch 217/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0134 - accuracy: 0.9992 - val_loss: 1.1971 - val_accuracy: 0.7923 - lr: 8.8923e-05\n",
      "Epoch 218/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0107 - accuracy: 0.9995 - val_loss: 1.1773 - val_accuracy: 0.7732 - lr: 8.8824e-05\n",
      "Epoch 219/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0105 - accuracy: 0.9989 - val_loss: 1.2195 - val_accuracy: 0.7750 - lr: 8.8725e-05\n",
      "Epoch 220/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0130 - accuracy: 0.9987 - val_loss: 1.2062 - val_accuracy: 0.7705 - lr: 8.8626e-05\n",
      "Epoch 221/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0107 - accuracy: 0.9998 - val_loss: 1.1569 - val_accuracy: 0.7796 - lr: 8.8526e-05\n",
      "Epoch 222/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0100 - accuracy: 0.9998 - val_loss: 1.1864 - val_accuracy: 0.7787 - lr: 8.8425e-05\n",
      "Epoch 223/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0138 - accuracy: 0.9978 - val_loss: 1.1725 - val_accuracy: 0.7823 - lr: 8.8325e-05\n",
      "Epoch 224/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.1452 - val_accuracy: 0.7796 - lr: 8.8224e-05\n",
      "Epoch 225/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1364 - val_accuracy: 0.7805 - lr: 8.8122e-05\n",
      "Epoch 226/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.1434 - val_accuracy: 0.7860 - lr: 8.8020e-05\n",
      "Epoch 227/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.1232 - val_accuracy: 0.7832 - lr: 8.7918e-05\n",
      "Epoch 228/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.1349 - val_accuracy: 0.7842 - lr: 8.7816e-05\n",
      "Epoch 229/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0084 - accuracy: 0.9995 - val_loss: 1.2388 - val_accuracy: 0.7832 - lr: 8.7713e-05\n",
      "Epoch 230/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0186 - accuracy: 0.9974 - val_loss: 1.2896 - val_accuracy: 0.7750 - lr: 8.7609e-05\n",
      "Epoch 231/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0143 - accuracy: 0.9978 - val_loss: 1.3089 - val_accuracy: 0.7878 - lr: 8.7506e-05\n",
      "Epoch 232/400\n",
      "320/320 [==============================] - 49s 152ms/step - loss: 0.0120 - accuracy: 0.9984 - val_loss: 1.2492 - val_accuracy: 0.7796 - lr: 8.7401e-05\n",
      "Epoch 233/400\n",
      "320/320 [==============================] - 49s 153ms/step - loss: 0.0092 - accuracy: 0.9995 - val_loss: 1.2040 - val_accuracy: 0.7769 - lr: 8.7297e-05\n",
      "Epoch 234/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.1706 - val_accuracy: 0.7705 - lr: 8.7192e-05\n",
      "Epoch 235/400\n",
      "320/320 [==============================] - 51s 160ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.1228 - val_accuracy: 0.7778 - lr: 8.7087e-05\n",
      "Epoch 236/400\n",
      "320/320 [==============================] - 48s 152ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.1936 - val_accuracy: 0.7559 - lr: 8.6982e-05\n",
      "Epoch 237/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.1578 - val_accuracy: 0.7741 - lr: 8.6876e-05\n",
      "Epoch 238/400\n",
      "320/320 [==============================] - 49s 153ms/step - loss: 0.0109 - accuracy: 0.9985 - val_loss: 1.2569 - val_accuracy: 0.7632 - lr: 8.6769e-05\n",
      "Epoch 239/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0085 - accuracy: 0.9998 - val_loss: 1.2809 - val_accuracy: 0.7805 - lr: 8.6663e-05\n",
      "Epoch 240/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0092 - accuracy: 0.9992 - val_loss: 1.1824 - val_accuracy: 0.7668 - lr: 8.6556e-05\n",
      "Epoch 241/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0102 - accuracy: 0.9992 - val_loss: 1.2634 - val_accuracy: 0.7741 - lr: 8.6448e-05\n",
      "Epoch 242/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1917 - val_accuracy: 0.7860 - lr: 8.6341e-05\n",
      "Epoch 243/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 1.1990 - val_accuracy: 0.7823 - lr: 8.6233e-05\n",
      "Epoch 244/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0084 - accuracy: 0.9998 - val_loss: 1.2364 - val_accuracy: 0.7541 - lr: 8.6124e-05\n",
      "Epoch 245/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0091 - accuracy: 0.9998 - val_loss: 1.2274 - val_accuracy: 0.7814 - lr: 8.6015e-05\n",
      "Epoch 246/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 1.2957 - val_accuracy: 0.7851 - lr: 8.5906e-05\n",
      "Epoch 247/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0084 - accuracy: 0.9995 - val_loss: 1.2242 - val_accuracy: 0.7851 - lr: 8.5797e-05\n",
      "Epoch 248/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0112 - accuracy: 0.9995 - val_loss: 1.2428 - val_accuracy: 0.7778 - lr: 8.5687e-05\n",
      "Epoch 249/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0158 - accuracy: 0.9974 - val_loss: 1.3396 - val_accuracy: 0.7769 - lr: 8.5577e-05\n",
      "Epoch 250/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0131 - accuracy: 0.9987 - val_loss: 1.2179 - val_accuracy: 0.7778 - lr: 8.5466e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0220 - accuracy: 0.9950 - val_loss: 1.2947 - val_accuracy: 0.7723 - lr: 8.5355e-05\n",
      "Epoch 252/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0212 - accuracy: 0.9958 - val_loss: 1.2489 - val_accuracy: 0.7851 - lr: 8.5244e-05\n",
      "Epoch 253/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0123 - accuracy: 0.9992 - val_loss: 1.2447 - val_accuracy: 0.7787 - lr: 8.5132e-05\n",
      "Epoch 254/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0118 - accuracy: 0.9992 - val_loss: 1.2709 - val_accuracy: 0.7851 - lr: 8.5021e-05\n",
      "Epoch 255/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0141 - accuracy: 0.9981 - val_loss: 1.3079 - val_accuracy: 0.7778 - lr: 8.4908e-05\n",
      "Epoch 256/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0103 - accuracy: 0.9994 - val_loss: 1.2122 - val_accuracy: 0.7860 - lr: 8.4796e-05\n",
      "Epoch 257/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0107 - accuracy: 0.9992 - val_loss: 1.2658 - val_accuracy: 0.7814 - lr: 8.4683e-05\n",
      "Epoch 258/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.1917 - val_accuracy: 0.7814 - lr: 8.4569e-05\n",
      "Epoch 259/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0077 - accuracy: 0.9998 - val_loss: 1.1703 - val_accuracy: 0.7842 - lr: 8.4456e-05\n",
      "Epoch 260/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0093 - accuracy: 0.9997 - val_loss: 1.2010 - val_accuracy: 0.7778 - lr: 8.4342e-05\n",
      "Epoch 261/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0076 - accuracy: 0.9998 - val_loss: 1.2253 - val_accuracy: 0.7851 - lr: 8.4227e-05\n",
      "Epoch 262/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 1.1892 - val_accuracy: 0.7769 - lr: 8.4113e-05\n",
      "Epoch 263/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0086 - accuracy: 0.9998 - val_loss: 1.2071 - val_accuracy: 0.7823 - lr: 8.3998e-05\n",
      "Epoch 264/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.2118 - val_accuracy: 0.7787 - lr: 8.3882e-05\n",
      "Epoch 265/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.2098 - val_accuracy: 0.7778 - lr: 8.3767e-05\n",
      "Epoch 266/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0099 - accuracy: 0.9995 - val_loss: 1.1577 - val_accuracy: 0.7823 - lr: 8.3651e-05\n",
      "Epoch 267/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.1625 - val_accuracy: 0.7805 - lr: 8.3534e-05\n",
      "Epoch 268/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0105 - accuracy: 0.9989 - val_loss: 1.2071 - val_accuracy: 0.7805 - lr: 8.3418e-05\n",
      "Epoch 269/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0085 - accuracy: 0.9997 - val_loss: 1.2191 - val_accuracy: 0.7769 - lr: 8.3301e-05\n",
      "Epoch 270/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.1696 - val_accuracy: 0.7860 - lr: 8.3183e-05\n",
      "Epoch 271/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1503 - val_accuracy: 0.7823 - lr: 8.3066e-05\n",
      "Epoch 272/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0088 - accuracy: 0.9995 - val_loss: 1.1718 - val_accuracy: 0.7842 - lr: 8.2948e-05\n",
      "Epoch 273/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.1576 - val_accuracy: 0.7814 - lr: 8.2829e-05\n",
      "Epoch 274/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1565 - val_accuracy: 0.7796 - lr: 8.2711e-05\n",
      "Epoch 275/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1635 - val_accuracy: 0.7796 - lr: 8.2592e-05\n",
      "Epoch 276/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0068 - accuracy: 0.9998 - val_loss: 1.1646 - val_accuracy: 0.7832 - lr: 8.2472e-05\n",
      "Epoch 277/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1591 - val_accuracy: 0.7805 - lr: 8.2353e-05\n",
      "Epoch 278/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1681 - val_accuracy: 0.7796 - lr: 8.2233e-05\n",
      "Epoch 279/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.1674 - val_accuracy: 0.7796 - lr: 8.2113e-05\n",
      "Epoch 280/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1641 - val_accuracy: 0.7769 - lr: 8.1992e-05\n",
      "Epoch 281/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1542 - val_accuracy: 0.7832 - lr: 8.1871e-05\n",
      "Epoch 282/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1824 - val_accuracy: 0.7796 - lr: 8.1750e-05\n",
      "Epoch 283/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.1813 - val_accuracy: 0.7787 - lr: 8.1629e-05\n",
      "Epoch 284/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1724 - val_accuracy: 0.7778 - lr: 8.1507e-05\n",
      "Epoch 285/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.1946 - val_accuracy: 0.7769 - lr: 8.1385e-05\n",
      "Epoch 286/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0063 - accuracy: 0.9998 - val_loss: 1.1917 - val_accuracy: 0.7796 - lr: 8.1262e-05\n",
      "Epoch 287/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 1.2044 - val_accuracy: 0.7814 - lr: 8.1139e-05\n",
      "Epoch 288/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.2054 - val_accuracy: 0.7760 - lr: 8.1016e-05\n",
      "Epoch 289/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.1884 - val_accuracy: 0.7814 - lr: 8.0893e-05\n",
      "Epoch 290/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.2254 - val_accuracy: 0.7814 - lr: 8.0769e-05\n",
      "Epoch 291/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 1.1893 - val_accuracy: 0.7851 - lr: 8.0645e-05\n",
      "Epoch 292/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0085 - accuracy: 0.9987 - val_loss: 1.2206 - val_accuracy: 0.7832 - lr: 8.0521e-05\n",
      "Epoch 293/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.2446 - val_accuracy: 0.7832 - lr: 8.0397e-05\n",
      "Epoch 294/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.1797 - val_accuracy: 0.7814 - lr: 8.0272e-05\n",
      "Epoch 295/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.1911 - val_accuracy: 0.7787 - lr: 8.0146e-05\n",
      "Epoch 296/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1725 - val_accuracy: 0.7732 - lr: 8.0021e-05\n",
      "Epoch 297/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1731 - val_accuracy: 0.7823 - lr: 7.9895e-05\n",
      "Epoch 298/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1976 - val_accuracy: 0.7750 - lr: 7.9769e-05\n",
      "Epoch 299/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0060 - accuracy: 0.9997 - val_loss: 1.2204 - val_accuracy: 0.7696 - lr: 7.9643e-05\n",
      "Epoch 300/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0068 - accuracy: 0.9998 - val_loss: 1.2145 - val_accuracy: 0.7851 - lr: 7.9516e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1992 - val_accuracy: 0.7832 - lr: 7.9389e-05\n",
      "Epoch 302/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1628 - val_accuracy: 0.7851 - lr: 7.9262e-05\n",
      "Epoch 303/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1684 - val_accuracy: 0.7814 - lr: 7.9135e-05\n",
      "Epoch 304/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1797 - val_accuracy: 0.7860 - lr: 7.9007e-05\n",
      "Epoch 305/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1875 - val_accuracy: 0.7832 - lr: 7.8879e-05\n",
      "Epoch 306/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1669 - val_accuracy: 0.7796 - lr: 7.8750e-05\n",
      "Epoch 307/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1904 - val_accuracy: 0.7832 - lr: 7.8622e-05\n",
      "Epoch 308/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.2000 - val_accuracy: 0.7787 - lr: 7.8493e-05\n",
      "Epoch 309/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0059 - accuracy: 0.9997 - val_loss: 1.2439 - val_accuracy: 0.7823 - lr: 7.8363e-05\n",
      "Epoch 310/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1945 - val_accuracy: 0.7842 - lr: 7.8234e-05\n",
      "Epoch 311/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1944 - val_accuracy: 0.7851 - lr: 7.8104e-05\n",
      "Epoch 312/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1840 - val_accuracy: 0.7796 - lr: 7.7974e-05\n",
      "Epoch 313/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0055 - accuracy: 0.9997 - val_loss: 1.2142 - val_accuracy: 0.7750 - lr: 7.7844e-05\n",
      "Epoch 314/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1932 - val_accuracy: 0.7860 - lr: 7.7713e-05\n",
      "Epoch 315/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0088 - accuracy: 0.9990 - val_loss: 1.2415 - val_accuracy: 0.7632 - lr: 7.7582e-05\n",
      "Epoch 316/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 1.2905 - val_accuracy: 0.7842 - lr: 7.7451e-05\n",
      "Epoch 317/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2492 - val_accuracy: 0.7823 - lr: 7.7320e-05\n",
      "Epoch 318/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.2200 - val_accuracy: 0.7842 - lr: 7.7188e-05\n",
      "Epoch 319/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2008 - val_accuracy: 0.7842 - lr: 7.7056e-05\n",
      "Epoch 320/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.2179 - val_accuracy: 0.7851 - lr: 7.6924e-05\n",
      "Epoch 321/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 1.1846 - val_accuracy: 0.7769 - lr: 7.6791e-05\n",
      "Epoch 322/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0086 - accuracy: 0.9989 - val_loss: 1.2155 - val_accuracy: 0.7814 - lr: 7.6659e-05\n",
      "Epoch 323/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 1.2206 - val_accuracy: 0.7851 - lr: 7.6526e-05\n",
      "Epoch 324/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1996 - val_accuracy: 0.7851 - lr: 7.6392e-05\n",
      "Epoch 325/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 1.3358 - val_accuracy: 0.7823 - lr: 7.6259e-05\n",
      "Epoch 326/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0276 - accuracy: 0.9932 - val_loss: 1.6554 - val_accuracy: 0.7559 - lr: 7.6125e-05\n",
      "Epoch 327/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0248 - accuracy: 0.9957 - val_loss: 1.2637 - val_accuracy: 0.7723 - lr: 7.5991e-05\n",
      "Epoch 328/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0109 - accuracy: 0.9995 - val_loss: 1.2575 - val_accuracy: 0.7760 - lr: 7.5857e-05\n",
      "Epoch 329/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0101 - accuracy: 0.9998 - val_loss: 1.2464 - val_accuracy: 0.7769 - lr: 7.5722e-05\n",
      "Epoch 330/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.4331 - val_accuracy: 0.7459 - lr: 7.5587e-05\n",
      "Epoch 331/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0110 - accuracy: 0.9987 - val_loss: 1.2390 - val_accuracy: 0.7632 - lr: 7.5452e-05\n",
      "Epoch 332/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0115 - accuracy: 0.9989 - val_loss: 1.3159 - val_accuracy: 0.7769 - lr: 7.5317e-05\n",
      "Epoch 333/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0093 - accuracy: 0.9992 - val_loss: 1.4209 - val_accuracy: 0.7805 - lr: 7.5181e-05\n",
      "Epoch 334/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0075 - accuracy: 0.9997 - val_loss: 1.2308 - val_accuracy: 0.7778 - lr: 7.5045e-05\n",
      "Epoch 335/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 1.2893 - val_accuracy: 0.7842 - lr: 7.4909e-05\n",
      "Epoch 336/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.2064 - val_accuracy: 0.7760 - lr: 7.4773e-05\n",
      "Epoch 337/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0078 - accuracy: 0.9997 - val_loss: 1.2392 - val_accuracy: 0.7769 - lr: 7.4636e-05\n",
      "Epoch 338/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 1.2464 - val_accuracy: 0.7741 - lr: 7.4500e-05\n",
      "Epoch 339/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.2123 - val_accuracy: 0.7787 - lr: 7.4363e-05\n",
      "Epoch 340/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 1.1998 - val_accuracy: 0.7714 - lr: 7.4225e-05\n",
      "Epoch 341/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0314 - accuracy: 0.9937 - val_loss: 1.3212 - val_accuracy: 0.7632 - lr: 7.4088e-05\n",
      "Epoch 342/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0140 - accuracy: 0.9981 - val_loss: 1.2922 - val_accuracy: 0.7823 - lr: 7.3950e-05\n",
      "Epoch 343/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0089 - accuracy: 0.9998 - val_loss: 1.2921 - val_accuracy: 0.7814 - lr: 7.3812e-05\n",
      "Epoch 344/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0086 - accuracy: 0.9994 - val_loss: 1.2159 - val_accuracy: 0.7641 - lr: 7.3674e-05\n",
      "Epoch 345/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.2083 - val_accuracy: 0.7732 - lr: 7.3535e-05\n",
      "Epoch 346/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0089 - accuracy: 0.9993 - val_loss: 1.2223 - val_accuracy: 0.7760 - lr: 7.3396e-05\n",
      "Epoch 347/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2405 - val_accuracy: 0.7851 - lr: 7.3258e-05\n",
      "Epoch 348/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2104 - val_accuracy: 0.7778 - lr: 7.3118e-05\n",
      "Epoch 349/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0170 - accuracy: 0.9964 - val_loss: 1.2197 - val_accuracy: 0.7805 - lr: 7.2979e-05\n",
      "Epoch 350/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.2880 - val_accuracy: 0.7805 - lr: 7.2839e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0080 - accuracy: 0.9997 - val_loss: 1.2757 - val_accuracy: 0.7741 - lr: 7.2700e-05\n",
      "Epoch 352/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 1.2339 - val_accuracy: 0.7796 - lr: 7.2559e-05\n",
      "Epoch 353/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2082 - val_accuracy: 0.7851 - lr: 7.2419e-05\n",
      "Epoch 354/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.2047 - val_accuracy: 0.7842 - lr: 7.2279e-05\n",
      "Epoch 355/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1768 - val_accuracy: 0.7823 - lr: 7.2138e-05\n",
      "Epoch 356/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1799 - val_accuracy: 0.7851 - lr: 7.1997e-05\n",
      "Epoch 357/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 1.1814 - val_accuracy: 0.7869 - lr: 7.1856e-05\n",
      "Epoch 358/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0088 - accuracy: 0.9995 - val_loss: 1.1896 - val_accuracy: 0.7814 - lr: 7.1714e-05\n",
      "Epoch 359/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1864 - val_accuracy: 0.7860 - lr: 7.1573e-05\n",
      "Epoch 360/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1747 - val_accuracy: 0.7851 - lr: 7.1431e-05\n",
      "Epoch 361/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 1.1775 - val_accuracy: 0.7832 - lr: 7.1289e-05\n",
      "Epoch 362/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1555 - val_accuracy: 0.7814 - lr: 7.1147e-05\n",
      "Epoch 363/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1822 - val_accuracy: 0.7796 - lr: 7.1004e-05\n",
      "Epoch 364/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1908 - val_accuracy: 0.7796 - lr: 7.0862e-05\n",
      "Epoch 365/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1794 - val_accuracy: 0.7823 - lr: 7.0719e-05\n",
      "Epoch 366/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 1.1759 - val_accuracy: 0.7860 - lr: 7.0576e-05\n",
      "Epoch 367/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.2102 - val_accuracy: 0.7832 - lr: 7.0432e-05\n",
      "Epoch 368/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0061 - accuracy: 0.9997 - val_loss: 1.2104 - val_accuracy: 0.7832 - lr: 7.0289e-05\n",
      "Epoch 369/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 1.2088 - val_accuracy: 0.7823 - lr: 7.0145e-05\n",
      "Epoch 370/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 1.2936 - val_accuracy: 0.7641 - lr: 7.0001e-05\n",
      "Epoch 371/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.2270 - val_accuracy: 0.7732 - lr: 6.9857e-05\n",
      "Epoch 372/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.2501 - val_accuracy: 0.7714 - lr: 6.9713e-05\n",
      "Epoch 373/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 1.2587 - val_accuracy: 0.7805 - lr: 6.9569e-05\n",
      "Epoch 374/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.2513 - val_accuracy: 0.7750 - lr: 6.9424e-05\n",
      "Epoch 375/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2188 - val_accuracy: 0.7851 - lr: 6.9279e-05\n",
      "Epoch 376/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1980 - val_accuracy: 0.7842 - lr: 6.9134e-05\n",
      "Epoch 377/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0082 - accuracy: 0.9993 - val_loss: 1.2226 - val_accuracy: 0.7887 - lr: 6.8989e-05\n",
      "Epoch 378/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0152 - accuracy: 0.9981 - val_loss: 1.3650 - val_accuracy: 0.7823 - lr: 6.8844e-05\n",
      "Epoch 379/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 1.3358 - val_accuracy: 0.7905 - lr: 6.8698e-05\n",
      "Epoch 380/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.2468 - val_accuracy: 0.7814 - lr: 6.8552e-05\n",
      "Epoch 381/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 1.2519 - val_accuracy: 0.7723 - lr: 6.8406e-05\n",
      "Epoch 382/400\n",
      "320/320 [==============================] - 47s 146ms/step - loss: 0.0110 - accuracy: 0.9981 - val_loss: 1.2009 - val_accuracy: 0.7851 - lr: 6.8260e-05\n",
      "Epoch 383/400\n",
      "320/320 [==============================] - 50s 156ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.1989 - val_accuracy: 0.7860 - lr: 6.8114e-05\n",
      "Epoch 384/400\n",
      "320/320 [==============================] - 50s 157ms/step - loss: 0.0071 - accuracy: 0.9997 - val_loss: 1.2219 - val_accuracy: 0.7805 - lr: 6.7967e-05\n",
      "Epoch 385/400\n",
      "320/320 [==============================] - 48s 151ms/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 1.2222 - val_accuracy: 0.7851 - lr: 6.7821e-05\n",
      "Epoch 386/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0073 - accuracy: 0.9998 - val_loss: 1.2318 - val_accuracy: 0.7805 - lr: 6.7674e-05\n",
      "Epoch 387/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.2096 - val_accuracy: 0.7832 - lr: 6.7527e-05\n",
      "Epoch 388/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2207 - val_accuracy: 0.7741 - lr: 6.7380e-05\n",
      "Epoch 389/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.2051 - val_accuracy: 0.7760 - lr: 6.7232e-05\n",
      "Epoch 390/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2121 - val_accuracy: 0.7769 - lr: 6.7085e-05\n",
      "Epoch 391/400\n",
      "320/320 [==============================] - 48s 150ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.2063 - val_accuracy: 0.7778 - lr: 6.6937e-05\n",
      "Epoch 392/400\n",
      "320/320 [==============================] - 48s 149ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2002 - val_accuracy: 0.7842 - lr: 6.6789e-05\n",
      "Epoch 393/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1728 - val_accuracy: 0.7823 - lr: 6.6641e-05\n",
      "Epoch 394/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0053 - accuracy: 0.9997 - val_loss: 1.1986 - val_accuracy: 0.7814 - lr: 6.6493e-05\n",
      "Epoch 395/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1928 - val_accuracy: 0.7832 - lr: 6.6344e-05\n",
      "Epoch 396/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.2561 - val_accuracy: 0.7869 - lr: 6.6196e-05\n",
      "Epoch 397/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 1.1688 - val_accuracy: 0.7814 - lr: 6.6047e-05\n",
      "Epoch 398/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 1.2206 - val_accuracy: 0.7878 - lr: 6.5898e-05\n",
      "Epoch 399/400\n",
      "320/320 [==============================] - 47s 147ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.2419 - val_accuracy: 0.7832 - lr: 6.5749e-05\n",
      "Epoch 400/400\n",
      "320/320 [==============================] - 47s 148ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 1.2295 - val_accuracy: 0.7760 - lr: 6.5600e-05\n"
     ]
    }
   ],
   "source": [
    "training = model.fit(x = x_train, y = y_train, batch_size = 8, \n",
    "                    epochs = 400, shuffle = True, verbose = 1, \n",
    "                    validation_split = 0.3,\n",
    "                    class_weight = class_weights,\n",
    "                    callbacks = [lr_scheduler_2, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.90      0.86       508\n",
      "           2       0.75      0.79      0.77       378\n",
      "           3       0.58      0.47      0.52       191\n",
      "           4       0.94      0.76      0.84       142\n",
      "\n",
      "    accuracy                           0.78      1219\n",
      "   macro avg       0.77      0.73      0.75      1219\n",
      "weighted avg       0.78      0.78      0.78      1219\n",
      "\n",
      "\u001b[32mConfusion Matrix\n",
      "[[457  26  22   3]\n",
      " [ 44 299  34   1]\n",
      " [ 32  67  89   3]\n",
      " [ 17   8   9 108]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_prob = model.predict(x_test)\n",
    "y_pred = np.argmax(predicted_prob, axis = 1)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cr = classification_report(enc.inverse_transform(y_test), y_pred+1)\n",
    "cm = confusion_matrix(enc.inverse_transform(y_test), y_pred+1)\n",
    "print('Classification Report', cr, sep = '\\n')\n",
    "print(Fore.GREEN+'Confusion Matrix', cm, '', sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_acc = training.history['val_accuracy']\n",
    "acc = training.history['accuracy']\n",
    "ep = np.arange(len(acc))+1\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure().patch.set_facecolor('white')\n",
    "plt.plot(ep, val_acc, label = 'val_acc')\n",
    "plt.plot(ep, acc, label = 'train_acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('metric')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss = training.history['val_loss']\n",
    "loss = training.history['loss']\n",
    "ep = np.arange(len(loss))+1\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure().patch.set_facecolor('white')\n",
    "plt.plot(ep, val_loss, label = 'val_loss')\n",
    "plt.plot(ep, loss, label = 'train_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('metric')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
